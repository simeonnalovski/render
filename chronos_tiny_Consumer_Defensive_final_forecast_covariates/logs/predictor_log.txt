Frequency 'YE' stored as 'YE-DEC'
Beginning AutoGluon training... Time limit = 600s
AutoGluon will save models to '/content/autogluon_models_local/chronos_tiny_Consumer_Defensive_final_forecast_covariates'
=================== System Info ===================
AutoGluon Version:  1.4.0
Python Version:     3.12.11
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #1 SMP PREEMPT_DYNAMIC Sun Mar 30 16:01:29 UTC 2025
CPU Count:          2
GPU Count:          0
Memory Avail:       10.39 GB / 12.67 GB (82.0%)
Disk Space Avail:   61.76 GB / 107.72 GB (57.3%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'freq': 'YE-DEC',
 'hyperparameters': {'Chronos': {'fine_tune': True,
                                 'hf_model_id': 'autogluon/chronos-t5-tiny'}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 5,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 600,
 'verbosity': 2}

Provided train_data has 17 rows, 1 time series. Median time series length is 17 (min=17, max=17). 

Provided data contains following columns:
	target: 'target'
	past_covariates:
		categorical:        []
		continuous (float): ['GDP (current US$)_country', 'GDP (current US$)_region', 'GDP per capi... US$)_country', 'GDP per capi...t US$)_region', 'GDP growth (...al %)_country', 'GDP growth (annual %)_region', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-09-05 11:14:30
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 600.0s of the 600.0s of remaining time.
Chronos[autogluon__chronos-bolt-small]/W0 ignores following hyperparameters: ['hf_model_id']. See the documentation for Chronos[autogluon__chronos-bolt-small]/W0 for the list of supported hyperparameters.
	Fine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.
	Saving fine-tuned model to /content/autogluon_models_local/chronos_tiny_Consumer_Defensive_final_forecast_covariates/models/Chronos[autogluon__chronos-bolt-small]/W0/fine-tuned-ckpt
	-0.2141       = Validation score (-MAPE)
	482.90  s     = Training runtime
	0.07    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 483.00 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.2141
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
